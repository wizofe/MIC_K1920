{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "MIC-Mini-Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wizofe/MIC_K1920/blob/master/MIC_Mini_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yoy2ANZuVal",
        "colab_type": "text"
      },
      "source": [
        "# CO407H - Medical Image Computing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-dz8CceuVao",
        "colab_type": "text"
      },
      "source": [
        "## Coursework - Age regression from brain MRI\n",
        "\n",
        "Predicting the age from a brain MRI scan is believed to have diagnostic value in the context of a number of pathologies that cause structural changes and damage to the brain. Assuming an accurate predictor of brain age can be trained based on a set of healthy subjects, the idea is then to compare the predicted age obtained on a new patient scan with the real age of that patient. Discrepancy between predicted and real age might indicate the presence of pathology and abnormal changes to the brain.\n",
        "\n",
        "The objective for the coursework is to implement two different supervised learning approaches for age regression from brain MRI data. Data from 652 subjects will be provided. Each approach will require a processing pipeline with different components that you will need to implement using methods that were discussed in the lectures and tutorials. There are dedicated sections in the Jupyter notebook for each approach which contain some detailed instructions and some hints and notes.\n",
        "\n",
        "For many tasks, you will find useful ideas and implementations in the tutorial notebooks. Make sure to add documentation to your code. Markers will find it easier to understand your reasoning when sufficiently detailed comments are provided in your implementations.\n",
        "\n",
        "#### Read the descriptions and provided code cells carefully and look out for the cells marked with 'TASK'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YN4nj5uuVap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5973951f-4da3-4854-b2ce-e2ad59ef1056"
      },
      "source": [
        "# Use full browser width\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZpYk--FuVav",
        "colab_type": "text"
      },
      "source": [
        "### Getting started\n",
        "\n",
        "The following cells provide some helper functions to load the data, and provide some overview and visualisation of the statistics over the population of 652 subjects. Let's start by loading the meta data, that is the data containing information about the subject IDs, their age, and gender."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIkwQroDuVaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the meta data using pandas\n",
        "import pandas as pd\n",
        "\n",
        "data_dir = '<path_to_project_data>'\n",
        "\n",
        "meta_data = pd.read_csv(data_dir + 'meta/clean_participant_data.csv')\n",
        "meta_data.head() # show the first five data entries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG4WWNIluVa0",
        "colab_type": "text"
      },
      "source": [
        "Let's have a look the the population statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY_OtD7puVa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.factorplot(x=\"gender_text\", data=meta_data, kind=\"count\")\n",
        "plt.title('Gender distribution')\n",
        "plt.xlabel('Gender')\n",
        "plt.show()\n",
        "\n",
        "sns.distplot(meta_data['age'], bins=[10,20,30,40,50,60,70,80,90])\n",
        "plt.title('Age distribution')\n",
        "plt.xlabel('Age')\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(range(len(meta_data['age'])),meta_data['age'], marker='.')\n",
        "plt.grid()\n",
        "plt.xlabel('Subject')\n",
        "plt.ylabel('Age')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-xg0G5IuVa4",
        "colab_type": "text"
      },
      "source": [
        "### Set up the image viewer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73jPT-LUuVa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import SimpleITK as sitk\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from ipywidgets import interact, fixed\n",
        "from IPython.display import display\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Calculate parameters low and high from window and level\n",
        "def wl_to_lh(window, level):\n",
        "    low = level - window/2\n",
        "    high = level + window/2\n",
        "    return low,high\n",
        "\n",
        "def display_image(img, x=None, y=None, z=None, window=None, level=None):\n",
        "    # Convert SimpleITK image to NumPy array\n",
        "    img_array = sitk.GetArrayFromImage(img)\n",
        "    \n",
        "    # Get image dimensions in millimetres\n",
        "    size = img.GetSize()\n",
        "    spacing = img.GetSpacing()\n",
        "    width  = size[0] * spacing[0]\n",
        "    height = size[1] * spacing[1]\n",
        "    depth  = size[2] * spacing[2]\n",
        "    \n",
        "    if x is None:\n",
        "        x = np.floor(size[0]/2).astype(int)\n",
        "    if y is None:\n",
        "        y = np.floor(size[1]/2).astype(int)\n",
        "    if z is None:\n",
        "        z = np.floor(size[2]/2).astype(int)\n",
        "    \n",
        "    if window is None:\n",
        "        window = np.max(img_array) - np.min(img_array)\n",
        "    \n",
        "    if level is None:\n",
        "        level = window / 2 + np.min(img_array)\n",
        "    \n",
        "    low,high = wl_to_lh(window,level)\n",
        "\n",
        "    # Display the orthogonal slices\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    ax1.imshow(img_array[z,:,:], cmap='gray', clim=(low, high), extent=(0, width, height, 0))\n",
        "    ax2.imshow(img_array[:,y,:], origin='lower', cmap='gray', clim=(low, high), extent=(0, width,  0, depth))\n",
        "    ax3.imshow(img_array[:,:,x], origin='lower', cmap='gray', clim=(low, high), extent=(0, height, 0, depth))\n",
        "\n",
        "    # Additionally display crosshairs\n",
        "    ax1.axhline(y * spacing[1], lw=1)\n",
        "    ax1.axvline(x * spacing[0], lw=1)\n",
        "    \n",
        "    ax2.axhline(z * spacing[2], lw=1)\n",
        "    ax2.axvline(x * spacing[0], lw=1)\n",
        "    \n",
        "    ax3.axhline(z * spacing[2], lw=1)\n",
        "    ax3.axvline(y * spacing[1], lw=1)\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "def interactive_view(img):\n",
        "    size = img.GetSize() \n",
        "    img_array = sitk.GetArrayFromImage(img)\n",
        "    interact(display_image,img=fixed(img),\n",
        "             x=(0, size[0] - 1),\n",
        "             y=(0, size[1] - 1),\n",
        "             z=(0, size[2] - 1),\n",
        "             window=(0,np.max(img_array) - np.min(img_array)),\n",
        "             level=(np.min(img_array),np.max(img_array)));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5OSUvvvuVa9",
        "colab_type": "text"
      },
      "source": [
        "### Imaging data\n",
        "\n",
        "Let's check out the imaging data that is available for each subject. This cell also shows how to retrieve data given a particular subject ID from the meta data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QkKQOnQuVa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "\n",
        "# Subject with index 0\n",
        "ID = meta_data['ID'][0]\n",
        "age = meta_data['age'][0]\n",
        "\n",
        "# Data folders\n",
        "image_dir = data_dir + 'images/'\n",
        "image_filenames = glob.glob(image_dir + '*.nii.gz')\n",
        "\n",
        "mask_dir = data_dir + 'masks/'\n",
        "mask_filenames = glob.glob(mask_dir + '*.nii.gz')\n",
        "\n",
        "greymatter_dir = data_dir + 'greymatter/'\n",
        "greymatter_filenames = glob.glob(greymatter_dir + '*.nii.gz')\n",
        "\n",
        "\n",
        "image_filename = [f for f in image_filenames if ID in f][0]\n",
        "img = sitk.ReadImage(image_filename)\n",
        "\n",
        "mask_filename = [f for f in mask_filenames if ID in f][0]\n",
        "msk = sitk.ReadImage(mask_filename)\n",
        "\n",
        "greymatter_filename = [f for f in greymatter_filenames if ID in f][0]\n",
        "gm = sitk.ReadImage(greymatter_filename)\n",
        "\n",
        "print('Imaging data of subject ' + ID + ' with age ' + str(age))\n",
        "\n",
        "print('\\nMR Image (used in part A)')\n",
        "display_image(img, window=400, level=200)\n",
        "\n",
        "print('Brain mask (used in part A)')\n",
        "display_image(msk)\n",
        "\n",
        "print('Spatially normalised grey matter maps (used in part B)')\n",
        "display_image(gm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuDI0i-luVbC",
        "colab_type": "text"
      },
      "source": [
        "## Part A: Volume-based regression using brain structure segmentation\n",
        "\n",
        "The first approach aims to regress the age of a subject from the volumes of brain tissues, including grey matter (GM), white matter (WM), and cerebrospinal fluid (CSF). It is known that with increasing age the ventricles enlarge (filled with CSF), while it is assumed that grey and white matter volume might decrease. However, as overall brain volume varies across individuals, taking the absolute volumes of tissues might not be predictive. Instead, relative volumes need to be computed as the ratios between each tissue volume and overall brain volume. To this end, a three-class brain tissue segmentation needs to be implemented and applied to the provided 652 brain scans. Brain masks are provided which have been generated with a state-of-the-art brain extraction tool from the FSL toolkit.\n",
        "\n",
        "Different regression techniques should be explored, and it might be beneficial to investigate what the best set of features is for this task. Are all volume features equally useful, or is it even better to combine some of them and create new features. How does a simple linear regression perform compared to a hypothesis with higher order polynomials? How about other regression methods such as support vector regression or regression trees? The accuracy of different methods should be evaluated using cross-validation, and average prediction accuracy should be reported.\n",
        "\n",
        "*Note:* For part A, only the MR images and the brain masks should be used from the imaging data. The spatially normalised grey matter maps are used in part B only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUOWp6KAuVbD",
        "colab_type": "text"
      },
      "source": [
        "### TASK A-1: Brain tissue segmentation\n",
        "\n",
        "Implement a brain tissue segmentation method which provides segmentations of GM, WM, and CSF. Apply this method to all 652 MR images, and calculate the three tissue volumes for each subject.\n",
        "\n",
        "*Hint:* For the segmentation method, you may want to make use of the provided brain masks to constrain your segmentation to brain voxels (compare tutorial 3).\n",
        "\n",
        "*Note:* For more efficient experimentation, you may want to initially restrict computations to the first five or so images. Once you're happy with the segmentation results, apply the method to all 652 images (which may take a while to run). You may also want to save the registration results using `sitk.WriteImage`, so you don't have to run the segmentation each time from scratch but instead load the stored results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXGlo4eUuVbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your implementation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqvUCg_7uVbH",
        "colab_type": "text"
      },
      "source": [
        "### TASK A-2: Feature calculation\n",
        "\n",
        "Implement a function that calculates volume features given the three tissue volumes and the overal brain volume (which can be calculated from the brain masks). You should use this function to construct a big matrix $X$ with a row for each subject and features across the columns.\n",
        "\n",
        "*Note:* You may need to experiment here what the best set of features is. Start with just calculating three simple features of relative tissue volumes. So you should initially construct an $X^{652 \\times 3}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnMAN9WzuVbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your implementation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb3aH82QuVbM",
        "colab_type": "text"
      },
      "source": [
        "### TASK A-3: Age regression and cross-validation\n",
        "\n",
        "Experiment with different regression methods from the [scikit-learn toolkit](http://scikit-learn.org/stable/supervised_learning.html#supervised-learning). Remmeber to construct the output vectur $y$ containing the age for each of the subjects.\n",
        "\n",
        "Evaluate the methods using two-fold [cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation) where the dataset of 652 subjects is split into two equally sized sets $(X_1,y_1)$ and $(X_2,y_2)$ which are used for training and testing in an alternating way (so each set is used as $(X_{\\text{train}},y_{\\text{train}})$ and $(X_{\\text{test}},y_{\\text{test}})$ exactly once).\n",
        "\n",
        "Try using at least two different regression methods.\n",
        "\n",
        "*Hint:* This [scikit-learn example](http://scikit-learn.org/stable/auto_examples/plot_cv_predict.html#sphx-glr-auto-examples-plot-cv-predict-py) might be useful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aeKxZktuVbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your implementation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Paw4qhShuVbR",
        "colab_type": "text"
      },
      "source": [
        "## Part B: Image-based regression using grey matter maps\n",
        "\n",
        "The second approach will make use of grey matter maps that have been already extracted from the set of MRI scans and aligned to a common reference space to obtain spatially normalised maps. For this, we have used an advanced, state-of-the-art neuroimaging toolkit, called SPM12. The reference space corresponds to the MNI atlas (compare slide 99 of the Segmentation lecture).\n",
        "\n",
        "Because the grey matter maps are spatially normalised, voxel locations across images from different subjects roughly correspond to the same anatomical locations. This means that each voxel location in the grey matter maps can be treated as an individual feature. Because those maps are quite large, there would be a very large number of features to deal with. A dimensionality reduction using PCA needs to be performed before training a suitable regressor on the low-dimensional feature representation obtained with PCA. It might also be beneficial to apply some pre-processing before running PCA, which should be explored. The implemented pipeline should be evaluated using cross-validation using the same data splits as in part A, so the two approaches can be directly compared.\n",
        "\n",
        "*Note:* For part B, only the spatially normalised grey matter maps should be used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZZPrC3EuVbS",
        "colab_type": "text"
      },
      "source": [
        "### TASK B-1: Pre-processing\n",
        "\n",
        "Before running PCA to reduce the dimensionality of the feature space for grey matter maps, it might be beneficial to run some pre-processing on the maps. In voxel-based analysis, such as training a regressor where each voxel location is a feature, it is common to apply some smoothing beforehand. This is to reduce noise and to compensate for errors of the spatial normalisation that had been applied to the maps.\n",
        "\n",
        "Because the maps are quite large, it might also be worthwile to explore whether downsampling could be performed, before PCA. This would further reduce the dimensionality, and might be even needed in the case where PCA on the orignial resolution runs into memory issues.\n",
        "\n",
        "Implement a function that performs suitable pre-processing on each grey matter map.\n",
        "\n",
        "*Hint:* Check out tutorial 1. You may want to save the pre-processed maps using `sitk.WriteImage` to avoid recomputation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V2TUm4suVbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your implementation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wt2Db7wuVbV",
        "colab_type": "text"
      },
      "source": [
        "### TASK B-2: Dimensionality reduction\n",
        "\n",
        "Implement dimensionality reduction for grey matter maps using [scitkit-learn's PCA](http://scikit-learn.org/stable/modules/decomposition.html#pca). PCA has an option to set the percentage of variance that needs to be preserved (by setting the parameter `n_components` to a value between 0 and 1). The number principal modes, that is the new dimensionality of the data, is then automatically determined. Try initially to preserve 95% of the variance (`n_components=0.95`).\n",
        "\n",
        "*Note:* When dimensionality reduction is used as pre-processing step for supervised learning, as in this case, it is important that PCA is fitted to the training data only, but then applied to both the training and testing data. So make sure your implementation consists of two separate steps, 1) fitting the PCA model to $X_{\\text{train}}$ (using the `fit` function), and 2) applying dimensionality reduction to $X_{\\text{train}}$ and $X_{\\text{test}}$ using the `transform` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMFVfuEIuVbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your implementation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW9ffluwuVbb",
        "colab_type": "text"
      },
      "source": [
        "### TASK B-3: Age regression and cross-validation\n",
        "\n",
        "Experiment with different regression methods from the [scikit-learn toolkit](http://scikit-learn.org/stable/supervised_learning.html#supervised-learning). Evaluate the methods using two-fold [cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation) in the same way as for approach A so results can be directly compared.\n",
        "\n",
        "Try using at least two different regression methods.\n",
        "\n",
        "*Note:* Remember, when you use cross-validation where you swap training and testing sets in each fold, you need to fit PCA to the training set of each fold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h96qv05CuVbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your implementation"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}